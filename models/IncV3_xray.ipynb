{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'F:/Xray_Gaus/train'\n",
    "TEST_DIR='F:/Xray_Gaus/test'\n",
    "VAL_DIR='F:/Xray_Gaus/val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 350 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training IDG\n",
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "train_gen = train_idg.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal_175_3','COVID-19'],\n",
    "    subset='training'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "val_gen = val_idg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal_20_3','COVID-19'],\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test Gen\n",
    "test_gen = test_idg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "    classes=['normal_20_3','COVID-19'],\n",
    "        #subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 51200)        0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 51200)        0           flatten[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 2048)         104859648   dropout[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 2048)         8192        dense[0][0]                      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 2048)         0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 2048)         8192        dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 2048)         0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            2049        dropout_2[0][0]                  \n==================================================================================================\nTotal params: 130,877,217\nTrainable params: 109,066,241\nNon-trainable params: 21,810,976\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = keras.applications.InceptionV3(\n",
    "    weights = 'imagenet',\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# se acopla el modelo\n",
    "model = keras.Model(base_model.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 33s 3s/step - loss: 1.0726 - accuracy: 0.6941 - precision: 0.6789 - recall: 0.6773 - val_loss: 82.2048 - val_accuracy: 0.4688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.1890 - accuracy: 0.8093 - precision: 0.8613 - recall: 0.7630 - val_loss: 6.8395 - val_accuracy: 0.7812 - val_precision: 0.9000 - val_recall: 0.6000\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3924 - accuracy: 0.9059 - precision: 0.9383 - recall: 0.8620 - val_loss: 17.5693 - val_accuracy: 0.6250 - val_precision: 1.0000 - val_recall: 0.2000\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2265 - accuracy: 0.9441 - precision: 0.9498 - recall: 0.9359 - val_loss: 3.5487 - val_accuracy: 0.7500 - val_precision: 1.0000 - val_recall: 0.5000\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.2109 - accuracy: 0.9201 - precision: 0.9526 - recall: 0.8962 - val_loss: 4.3785 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.6429\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n // val_gen.batch_size\n",
    "\n",
    "history=model.fit(x = train_gen,\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_gen,\n",
    "          validation_steps = STEP_SIZE_VALID,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: F:/X_ray_Models/IncV3_xray_model\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [1.1137995719909668,\n",
       "  1.0797934532165527,\n",
       "  0.4633556008338928,\n",
       "  0.2702917754650116,\n",
       "  0.22272901237010956],\n",
       " 'accuracy': [0.7610062956809998,\n",
       "  0.8207547068595886,\n",
       "  0.9056603908538818,\n",
       "  0.9402515888214111,\n",
       "  0.9276729822158813],\n",
       " 'precision': [0.7564102411270142,\n",
       "  0.846666693687439,\n",
       "  0.9189189076423645,\n",
       "  0.9548386931419373,\n",
       "  0.9235668778419495],\n",
       " 'recall': [0.7564102411270142,\n",
       "  0.7888198494911194,\n",
       "  0.8831169009208679,\n",
       "  0.925000011920929,\n",
       "  0.9294871687889099],\n",
       " 'val_loss': [82.20478057861328,\n",
       "  6.8395304679870605,\n",
       "  17.569278717041016,\n",
       "  3.5487112998962402,\n",
       "  4.378469944000244],\n",
       " 'val_accuracy': [0.46875, 0.78125, 0.625, 0.75, 0.84375],\n",
       " 'val_precision': [0.0, 0.8999999761581421, 1.0, 1.0, 1.0],\n",
       " 'val_recall': [0.0,\n",
       "  0.6000000238418579,\n",
       "  0.20000000298023224,\n",
       "  0.5,\n",
       "  0.6428571343421936]}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.save('F:/X_ray_Models/IncV3_xray_model')\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 2s 344ms/step - loss: 3.3259 - accuracy: 0.8250 - precision: 1.0000 - recall: 0.6500\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_gen, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 3s 265ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "\n",
    "#y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>=0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.48      0.65      0.55        20\n           1       0.46      0.30      0.36        20\n\n    accuracy                           0.48        40\n   macro avg       0.47      0.47      0.46        40\nweighted avg       0.47      0.47      0.46        40\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[13,  7],\n",
       "       [14,  6]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  }
 ]
}