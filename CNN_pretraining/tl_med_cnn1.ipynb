{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'F:/Xray_Gaus/train'\n",
    "TEST_DIR='F:/Xray_Gaus/test'\n",
    "VAL_DIR='F:/Xray_Gaus/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5805 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training IDG\n",
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "# Training Gen\n",
    "train_gen = train_idg.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    classes=['normal','COVID-19'],\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 905 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "val_gen = val_idg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal','COVID-19'],\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 905 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test Gen\n",
    "test_gen = test_idg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "    classes=['normal','COVID-19'],\n",
    "        #subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = keras.models.load_model(\"F:/Xray_Gaus/CNN_binary_wt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "epochs=5\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"tl_med_cnn.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=1e-04                 #0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "90/90 [==============================] - 261s 3s/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 12.3492 - val_accuracy: 0.0346\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 308s 3s/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.3869 - val_accuracy: 0.8717\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n // val_gen.batch_size\n",
    "\n",
    "history=pretrained_model.fit(x = train_gen,\n",
    "          batch_size=batch_size,\n",
    "          epochs=2,\n",
    "          callbacks=callbacks,\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_gen,\n",
    "          validation_steps = STEP_SIZE_VALID )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29/29 [==============================] - 22s 765ms/step - loss: 0.0314 - accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "results = pretrained_model.evaluate(test_gen, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29/29 [==============================] - 15s 534ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = pretrained_model.predict(test_gen, verbose=1)\n",
    "#y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>=0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.98      0.97      0.98       885\n           1       0.07      0.10      0.09        20\n\n    accuracy                           0.95       905\n   macro avg       0.53      0.54      0.53       905\nweighted avg       0.96      0.95      0.96       905\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: F:/Xray_Gaus/tlCNN_binary_wt\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [0.03113209269940853, 0.01964982971549034],\n",
       " 'accuracy': [0.9914649128913879, 0.9932067394256592],\n",
       " 'val_loss': [12.349210739135742, 0.3869269788265228],\n",
       " 'val_accuracy': [0.0345982126891613, 0.8716517686843872],\n",
       " 'lr': [0.001, 0.001]}"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "pretrained_model.save('F:/Xray_Gaus/tlCNN_binary_wt')\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}