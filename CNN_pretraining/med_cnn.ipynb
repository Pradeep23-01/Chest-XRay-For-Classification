{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'F:/Xray_Gaus/train'\n",
    "TEST_DIR='F:/Xray_Gaus/test'\n",
    "VAL_DIR='F:/Xray_Gaus/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 9534 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training IDG\n",
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "# Training Gen\n",
    "train_gen = train_idg.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    classes=['normal','pneumonia'],\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1490 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "val_gen = val_idg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal','pneumonia'],\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1489 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test Gen\n",
    "test_gen = test_idg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "    classes=['normal','pneumonia'],\n",
    "        #subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import kerastuner as kt\n",
    "from keras.layers import Convolution2D,Flatten,Dense,Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 224, 224, 25)      1900      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 112, 112, 25)      0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 50)        31300     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 28, 28, 50)        0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 28, 28, 50)        200       \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 14, 14, 70)        31570     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 7, 7, 70)          0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 7, 7, 70)          280       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3430)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 100)               343100    \n_________________________________________________________________\ndense_4 (Dense)              (None, 100)               10100     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 418,551\nTrainable params: 418,311\nNon-trainable params: 240\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "\n",
    "# build a sequential model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# fit on data for 30 epochs\n",
    "#model.fit_generator(train, epochs=30, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "148/148 [==============================] - 587s 4s/step - loss: 0.4902 - accuracy: 0.7688 - val_loss: 1.0751 - val_accuracy: 0.4531\n",
      "Epoch 2/5\n",
      "148/148 [==============================] - 508s 3s/step - loss: 0.3226 - accuracy: 0.8694 - val_loss: 0.6206 - val_accuracy: 0.6929\n",
      "Epoch 3/5\n",
      "148/148 [==============================] - 530s 4s/step - loss: 0.2867 - accuracy: 0.8845 - val_loss: 0.7123 - val_accuracy: 0.6719\n",
      "Epoch 4/5\n",
      "148/148 [==============================] - 509s 3s/step - loss: 0.2910 - accuracy: 0.8869 - val_loss: 2.4463 - val_accuracy: 0.4266\n",
      "Epoch 5/5\n",
      "148/148 [==============================] - 515s 3s/step - loss: 0.2673 - accuracy: 0.8977 - val_loss: 0.4315 - val_accuracy: 0.8397\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n // val_gen.batch_size\n",
    "\n",
    "history=model.fit(x = train_gen,\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_gen,\n",
    "          validation_steps = STEP_SIZE_VALID,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: F:/Xray_Gaus/CNN_binary_wt\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [0.4168108403682709,\n",
       "  0.322676420211792,\n",
       "  0.2978545129299164,\n",
       "  0.2832720875740051,\n",
       "  0.27223294973373413],\n",
       " 'accuracy': [0.8159450888633728,\n",
       "  0.8710665106773376,\n",
       "  0.8816261887550354,\n",
       "  0.8895459175109863,\n",
       "  0.8942977786064148],\n",
       " 'val_loss': [1.075124740600586,\n",
       "  0.6205593943595886,\n",
       "  0.7122825384140015,\n",
       "  2.4463088512420654,\n",
       "  0.43149393796920776],\n",
       " 'val_accuracy': [0.453125,\n",
       "  0.6929348111152649,\n",
       "  0.671875,\n",
       "  0.426630437374115,\n",
       "  0.8396739363670349]}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "model.save('F:/Xray_Gaus/CNN_binary_wt')\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "47/47 [==============================] - 39s 844ms/step - loss: 0.3263 - accuracy: 0.8899\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_gen, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "47/47 [==============================] - 18s 376ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "#y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "#y_pred=model.predict(X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>=0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.61      0.67      0.64       885\n           1       0.44      0.38      0.40       604\n\n    accuracy                           0.55      1489\n   macro avg       0.52      0.52      0.52      1489\nweighted avg       0.54      0.55      0.54      1489\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def create_model(hyperparam):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Convolution2D(\n",
    "    filters=hyperparam.Int('convolution_1',min_value=32, max_value=128, step=16), kernel_size=hyperparam.Choice('convolution_1', values     = [3,6]),\n",
    "    activation='relu',input_shape=(IMG_SIZE,IMG_SIZE,3)\n",
    "                            )),\n",
    "\n",
    "    model.add(Convolution2D(\n",
    "    filters=hyperparam.Int('convolution_2', min_value=64, max_value=128, step=16),kernel_size=hyperparam.Choice('convolution_2', values     = [3,6]),\n",
    "    activation='relu'\n",
    "                            )),\n",
    "\n",
    "    model.add(Convolution2D(\n",
    "    filters=hyperparam.Int('convolution_3', min_value=64, max_value=128, step=16),kernel_size=hyperparam.Choice('convolution_3', values = [3,6]),\n",
    "    activation='relu'\n",
    "                            )),\n",
    "\n",
    "    model.add(Flatten()),\n",
    "    model.add(Dense(1)),\n",
    "    model.add(Activation(\"softmax\")),\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hyperparam.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tuner_search=RandomSearch(create_model,\n",
    "                       objective='val_accuracy',\n",
    "                       max_trials=5,directory='output',project_name=\"Med\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "es\\tensorflow\\python\\training\\tracking\\base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 590, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2015, in __init__\n",
      "    self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1856, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "Invalid model 1/5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1853, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-22-ecbf3471a0c1>\", line 14, in create_model\n",
      "    model.add(Convolution2D(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 590, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2015, in __init__\n",
      "    self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1856, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "Invalid model 2/5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1853, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-22-ecbf3471a0c1>\", line 14, in create_model\n",
      "    model.add(Convolution2D(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 590, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2015, in __init__\n",
      "    self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1856, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "Invalid model 3/5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1853, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-22-ecbf3471a0c1>\", line 14, in create_model\n",
      "    model.add(Convolution2D(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 590, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2015, in __init__\n",
      "    self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1856, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "Invalid model 4/5\n",
      "Invalid model 5/5\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1853, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\", line 104, in build\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"<ipython-input-22-ecbf3471a0c1>\", line 14, in create_model\n",
      "    model.add(Convolution2D(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 968, in conv2d\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 590, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2015, in __init__\n",
      "    self._c_op = _create_c_op(self._graph, node_def, inputs,\n",
      "  File \"C:\\Users\\mprad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1856, in _create_c_op\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Too many failed attempts to build model.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1852\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-ecbf3471a0c1>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(hyperparam)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     model.add(Convolution2D(\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convolution_3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convolution_3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    222\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                                 input_list)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     name=None):\n\u001b[1;32m-> 1013\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1144\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2596\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2597\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2598\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    967\u001b[0m   \u001b[0mdilations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdilations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m    969\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3528\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2016\u001b[0m                                 control_input_ops, op_def)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1855\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 80 from 34 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,34,34,80], [80,80,80,80].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3a759835bb26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36m_build_wrapper\u001b[1;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;31m# to the search space.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_fail_streak\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     raise RuntimeError(\n\u001b[0m\u001b[0;32m    113\u001b[0m                         'Too many failed attempts to build model.')\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Too many failed attempts to build model."
     ]
    }
   ],
   "source": [
    "tuner_search.search(train_gen,epochs=5,validation_data=val_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}