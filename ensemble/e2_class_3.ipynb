{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'F:/Xray_Gaus/train'\n",
    "TEST_DIR='F:/Xray_Gaus/test'\n",
    "VAL_DIR='F:/Xray_Gaus/val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 526 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training IDG\n",
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "train_gen = train_idg.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal_175_2','pneumonia_175','COVID-19'],\n",
    "    subset='training'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "val_gen = val_idg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    classes=['normal_20_2','pneumonia_20','COVID-19'],\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test Gen\n",
    "test_gen = test_idg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "    classes=['normal_20_2','pneumonia_20','COVID-19'],\n",
    "        #subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "___________\nconv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n                                                                 conv5_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n                                                                 conv5_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n                                                                 conv5_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n                                                                 conv5_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n                                                                 conv5_block25_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n                                                                 conv5_block26_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n                                                                 conv5_block27_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n                                                                 conv5_block28_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n                                                                 conv5_block29_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n                                                                 conv5_block30_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n                                                                 conv5_block31_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n                                                                 conv5_block32_2_conv[0][0]       \n__________________________________________________________________________________________________\nbn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n__________________________________________________________________________________________________\nrelu (Activation)               (None, 7, 7, 1664)   0           bn[0][0]                         \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 81536)        0           relu[0][0]                       \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 81536)        0           flatten[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 2048)         166987776   dropout[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 2048)         0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 3)            6147        dropout_2[0][0]                  \n==================================================================================================\nTotal params: 183,849,539\nTrainable params: 171,198,467\nNon-trainable params: 12,651,072\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_input = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = keras.applications.DenseNet169(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_1 = keras.Model(base_model.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 25088)             0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 2048)              51382272  \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 2048)              8192      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 2048)              4196352   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 2048)              8192      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 3)                 6147      \n=================================================================\nTotal params: 75,625,539\nTrainable params: 55,592,963\nNon-trainable params: 20,032,576\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "\n",
    "base_model1 = keras.applications.VGG19(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model1.trainable = False\n",
    "\n",
    "x1 = base_model1.output\n",
    "x1 = keras.layers.Flatten()(x1)\n",
    "x1 = keras.layers.Dropout(0.4)(x1)\n",
    "x1 = keras.layers.Dense(2048, activation='relu')(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dropout(0.4)(x1)\n",
    "x1 = keras.layers.Dense(2048, activation='relu')(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dropout(0.2)(x1)\n",
    "outputs = keras.layers.Dense(3, activation='softmax')(x1)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_2 = keras.Model(base_model1.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 51200)        0           flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 2048)         104859648   dropout_6[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_98 (BatchNo (None, 2048)         8192        dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 2048)         0           batch_normalization_98[0][0]     \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 2048)         4196352     dropout_7[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_99 (BatchNo (None, 2048)         8192        dense_7[0][0]                    \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 2048)         0           batch_normalization_99[0][0]     \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 3)            6147        dropout_8[0][0]                  \n==================================================================================================\nTotal params: 130,881,315\nTrainable params: 109,070,339\nNon-trainable params: 21,810,976\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model2 = keras.applications.InceptionV3(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model2.trainable = False\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = keras.layers.Flatten()(x2)\n",
    "x2 = keras.layers.Dropout(0.4)(x2)\n",
    "x2 = keras.layers.Dense(2048, activation='relu')(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dropout(0.4)(x2)\n",
    "x2 = keras.layers.Dense(2048, activation='relu')(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dropout(0.2)(x2)\n",
    "outputs = keras.layers.Dense(3, activation='softmax')(x2)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_3 = keras.Model(base_model2.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "___________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1664)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 81536)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25088)        0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 81536)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 25088)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 51200)        0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         166987776   dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         51382272    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         104859648   dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2048)         8192        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 2048)         8192        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2048)         0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2048)         4196352     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2048)         8192        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 2048)         8192        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2048)         0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            6147        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3)            6147        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            6147        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 9)            0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 9)            90          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            30          dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 390,356,513\n",
      "Trainable params: 335,861,889\n",
      "Non-trainable params: 54,494,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mergedOutput = tf.keras.layers.Concatenate()([model_1.output,model_2.output,model_3.output])\n",
    "\n",
    "hidden = tf.keras.layers.Dense(9, activation='relu')(mergedOutput)\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(hidden)\n",
    "model = tf.keras.Model(inputs=new_input, outputs=output)\n",
    "                # plot graph of ensemble\n",
    "            #plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "                # compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 311s 18s/step - loss: 1.0631 - accuracy: 0.4696 - val_loss: 1.1487 - val_accuracy: 0.4062\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 224s 14s/step - loss: 1.0016 - accuracy: 0.5312 - val_loss: 1.2828 - val_accuracy: 0.2812\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 380s 24s/step - loss: 0.9371 - accuracy: 0.5732 - val_loss: 1.1581 - val_accuracy: 0.4062\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 173s 11s/step - loss: 0.9204 - accuracy: 0.5532 - val_loss: 1.1301 - val_accuracy: 0.2812\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 226s 15s/step - loss: 0.8725 - accuracy: 0.7333 - val_loss: 1.2201 - val_accuracy: 0.3438\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n // val_gen.batch_size\n",
    "\n",
    "history=model.fit(x = train_gen,\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_gen,\n",
    "          validation_steps = STEP_SIZE_VALID,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 25s 12s/step - loss: 1.1783 - accuracy: 0.3833\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_gen, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: F:/X_ray_Models/e2_class3_xray_model_174_2\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [1.0231479406356812,\n",
       "  0.9676163196563721,\n",
       "  0.9238491654396057,\n",
       "  0.9090377688407898,\n",
       "  0.8692166209220886],\n",
       " 'accuracy': [0.4898785352706909,\n",
       "  0.5809716582298279,\n",
       "  0.5850202441215515,\n",
       "  0.6113360524177551,\n",
       "  0.73886638879776],\n",
       " 'val_loss': [1.1487349271774292,\n",
       "  1.2827742099761963,\n",
       "  1.1580848693847656,\n",
       "  1.1300809383392334,\n",
       "  1.220134973526001],\n",
       " 'val_accuracy': [0.40625, 0.28125, 0.40625, 0.28125, 0.34375]}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.save('F:/X_ray_Models/e2_class3_xray_model_174_2')\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 33s 9s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.32      0.90      0.47        20\n           1       0.50      0.05      0.09        20\n           2       0.00      0.00      0.00        20\n\n    accuracy                           0.32        60\n   macro avg       0.27      0.32      0.19        60\nweighted avg       0.27      0.32      0.19        60\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[18,  1,  1],\n",
       "       [18,  1,  1],\n",
       "       [20,  0,  0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  }
 ]
}