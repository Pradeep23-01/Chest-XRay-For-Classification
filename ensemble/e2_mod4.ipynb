{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b64de0ba76e769a7c3088015f258876bdb4240a199c36c507f14d2fb10bd5d74"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'F:/Xray_Gaus/train'\n",
    "TEST_DIR='F:/Xray_Gaus/test'\n",
    "VAL_DIR='F:/Xray_Gaus/val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (224,224, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 350 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training IDG\n",
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "train_gen = train_idg.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal_175_2','COVID-19'],\n",
    "    subset='training'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1, \n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Training Gen\n",
    "val_gen = val_idg.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    classes=['normal_20_2','COVID-19'],\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_idg = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Test Gen\n",
    "test_gen = test_idg.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "    classes=['normal_20_2','COVID-19'],\n",
    "        #subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "___________\nconv5_block21_0_relu (Activatio (None, 7, 7, 1280)   0           conv5_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block21_1_conv (Conv2D)   (None, 7, 7, 128)    163840      conv5_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block21_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block21_concat (Concatena (None, 7, 7, 1312)   0           conv5_block20_concat[0][0]       \n                                                                 conv5_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_0_bn (BatchNormal (None, 7, 7, 1312)   5248        conv5_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_0_relu (Activatio (None, 7, 7, 1312)   0           conv5_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block22_1_conv (Conv2D)   (None, 7, 7, 128)    167936      conv5_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block22_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block22_concat (Concatena (None, 7, 7, 1344)   0           conv5_block21_concat[0][0]       \n                                                                 conv5_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_0_bn (BatchNormal (None, 7, 7, 1344)   5376        conv5_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_0_relu (Activatio (None, 7, 7, 1344)   0           conv5_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block23_1_conv (Conv2D)   (None, 7, 7, 128)    172032      conv5_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block23_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block23_concat (Concatena (None, 7, 7, 1376)   0           conv5_block22_concat[0][0]       \n                                                                 conv5_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_0_bn (BatchNormal (None, 7, 7, 1376)   5504        conv5_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_0_relu (Activatio (None, 7, 7, 1376)   0           conv5_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block24_1_conv (Conv2D)   (None, 7, 7, 128)    176128      conv5_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block24_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block24_concat (Concatena (None, 7, 7, 1408)   0           conv5_block23_concat[0][0]       \n                                                                 conv5_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_0_bn (BatchNormal (None, 7, 7, 1408)   5632        conv5_block24_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_0_relu (Activatio (None, 7, 7, 1408)   0           conv5_block25_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block25_1_conv (Conv2D)   (None, 7, 7, 128)    180224      conv5_block25_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block25_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block25_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block25_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block25_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block25_concat (Concatena (None, 7, 7, 1440)   0           conv5_block24_concat[0][0]       \n                                                                 conv5_block25_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_0_bn (BatchNormal (None, 7, 7, 1440)   5760        conv5_block25_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_0_relu (Activatio (None, 7, 7, 1440)   0           conv5_block26_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block26_1_conv (Conv2D)   (None, 7, 7, 128)    184320      conv5_block26_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block26_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block26_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block26_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block26_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block26_concat (Concatena (None, 7, 7, 1472)   0           conv5_block25_concat[0][0]       \n                                                                 conv5_block26_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_0_bn (BatchNormal (None, 7, 7, 1472)   5888        conv5_block26_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_0_relu (Activatio (None, 7, 7, 1472)   0           conv5_block27_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block27_1_conv (Conv2D)   (None, 7, 7, 128)    188416      conv5_block27_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block27_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block27_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block27_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block27_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block27_concat (Concatena (None, 7, 7, 1504)   0           conv5_block26_concat[0][0]       \n                                                                 conv5_block27_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_0_bn (BatchNormal (None, 7, 7, 1504)   6016        conv5_block27_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_0_relu (Activatio (None, 7, 7, 1504)   0           conv5_block28_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block28_1_conv (Conv2D)   (None, 7, 7, 128)    192512      conv5_block28_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block28_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block28_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block28_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block28_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block28_concat (Concatena (None, 7, 7, 1536)   0           conv5_block27_concat[0][0]       \n                                                                 conv5_block28_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_0_bn (BatchNormal (None, 7, 7, 1536)   6144        conv5_block28_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_0_relu (Activatio (None, 7, 7, 1536)   0           conv5_block29_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block29_1_conv (Conv2D)   (None, 7, 7, 128)    196608      conv5_block29_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block29_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block29_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block29_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block29_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block29_concat (Concatena (None, 7, 7, 1568)   0           conv5_block28_concat[0][0]       \n                                                                 conv5_block29_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_0_bn (BatchNormal (None, 7, 7, 1568)   6272        conv5_block29_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_0_relu (Activatio (None, 7, 7, 1568)   0           conv5_block30_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block30_1_conv (Conv2D)   (None, 7, 7, 128)    200704      conv5_block30_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block30_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block30_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block30_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block30_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block30_concat (Concatena (None, 7, 7, 1600)   0           conv5_block29_concat[0][0]       \n                                                                 conv5_block30_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_0_bn (BatchNormal (None, 7, 7, 1600)   6400        conv5_block30_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_0_relu (Activatio (None, 7, 7, 1600)   0           conv5_block31_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block31_1_conv (Conv2D)   (None, 7, 7, 128)    204800      conv5_block31_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block31_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block31_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n                                                                 conv5_block31_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n                                                                 conv5_block32_2_conv[0][0]       \n__________________________________________________________________________________________________\nbn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n__________________________________________________________________________________________________\nrelu (Activation)               (None, 7, 7, 1664)   0           bn[0][0]                         \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 81536)        0           relu[0][0]                       \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 81536)        0           flatten[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 2048)         166987776   dropout[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 2048)         0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            2049        dropout_2[0][0]                  \n==================================================================================================\nTotal params: 183,845,441\nTrainable params: 171,194,369\nNon-trainable params: 12,651,072\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_input = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = keras.applications.DenseNet169(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.4)(x)\n",
    "x = keras.layers.Dense(2048, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_1 = keras.Model(base_model.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 25088)             0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 2048)              51382272  \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 2048)              8192      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 2048)              4196352   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 2048)              8192      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 2049      \n=================================================================\nTotal params: 75,621,441\nTrainable params: 55,588,865\nNon-trainable params: 20,032,576\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "base_model1 = keras.applications.VGG19(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model1.trainable = False\n",
    "\n",
    "x1 = base_model1.output\n",
    "x1 = keras.layers.Flatten()(x1)\n",
    "x1 = keras.layers.Dropout(0.4)(x1)\n",
    "x1 = keras.layers.Dense(2048, activation='relu')(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dropout(0.4)(x1)\n",
    "x1 = keras.layers.Dense(2048, activation='relu')(x1)\n",
    "x1 = keras.layers.BatchNormalization()(x1)\n",
    "x1 = keras.layers.Dropout(0.2)(x1)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x1)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_2 = keras.Model(base_model1.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 51200)        0           flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 2048)         104859648   dropout_6[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_98 (BatchNo (None, 2048)         8192        dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 2048)         0           batch_normalization_98[0][0]     \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 2048)         4196352     dropout_7[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_99 (BatchNo (None, 2048)         8192        dense_7[0][0]                    \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 2048)         0           batch_normalization_99[0][0]     \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 1)            2049        dropout_8[0][0]                  \n==================================================================================================\nTotal params: 130,877,217\nTrainable params: 109,066,241\nNon-trainable params: 21,810,976\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model2 = keras.applications.InceptionV3(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model2.trainable = False\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = keras.layers.Flatten()(x2)\n",
    "x2 = keras.layers.Dropout(0.4)(x2)\n",
    "x2 = keras.layers.Dense(2048, activation='relu')(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dropout(0.4)(x2)\n",
    "x2 = keras.layers.Dense(2048, activation='relu')(x2)\n",
    "x2 = keras.layers.BatchNormalization()(x2)\n",
    "x2 = keras.layers.Dropout(0.2)(x2)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_3 = keras.Model(base_model2.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0][0]     \n__________________________________________________________________________________________________\nmixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n                                                                 activation_63[0][0]              \n                                                                 activation_68[0][0]              \n                                                                 activation_69[0][0]              \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nactivation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nactivation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nactivation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nactivation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nactivation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_75[0][0]     \n__________________________________________________________________________________________________\nactivation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n__________________________________________________________________________________________________\nmixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n                                                                 activation_75[0][0]              \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n__________________________________________________________________________________________________\nconv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\nconv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n__________________________________________________________________________________________________\nconv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nmixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n                                                                 activation_79[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n                                                                 activation_83[0][0]              \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nmixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n                                                                 mixed9_0[0][0]                   \n                                                                 concatenate[0][0]                \n                                                                 activation_84[0][0]              \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n__________________________________________________________________________________________________\naverage_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nmixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n                                                                 activation_88[0][0]              \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n                                                                 activation_92[0][0]              \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nmixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n                                                                 mixed9_1[0][0]                   \n                                                                 concatenate_1[0][0]              \n                                                                 activation_93[0][0]              \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n__________________________________________________________________________________________________\ndropout_9 (Dropout)             (None, 51200)        0           flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 2048)         104859648   dropout_9[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_100 (BatchN (None, 2048)         8192        dense_9[0][0]                    \n__________________________________________________________________________________________________\ndropout_10 (Dropout)            (None, 2048)         0           batch_normalization_100[0][0]    \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 2048)         4196352     dropout_10[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_101 (BatchN (None, 2048)         8192        dense_10[0][0]                   \n__________________________________________________________________________________________________\ndropout_11 (Dropout)            (None, 2048)         0           batch_normalization_101[0][0]    \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 1)            2049        dropout_11[0][0]                 \n==================================================================================================\nTotal params: 130,877,217\nTrainable params: 109,066,241\nNon-trainable params: 21,810,976\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model3 = keras.applications.ResNet50(\n",
    "    weights = 'imagenet',\n",
    "    #input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,input_tensor=new_input)\n",
    "\n",
    "base_model3.trainable = False\n",
    "\n",
    "x3 = base_model2.output\n",
    "x3 = keras.layers.Flatten()(x3)\n",
    "x3 = keras.layers.Dropout(0.4)(x3)\n",
    "x3 = keras.layers.Dense(2048, activation='relu')(x3)\n",
    "x3 = keras.layers.BatchNormalization()(x3)\n",
    "x3 = keras.layers.Dropout(0.4)(x3)\n",
    "x3 = keras.layers.Dense(2048, activation='relu')(x3)\n",
    "x3 = keras.layers.BatchNormalization()(x3)\n",
    "x3 = keras.layers.Dropout(0.2)(x3)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x3)\n",
    "\n",
    "# se acopla el modelo\n",
    "model_4 = keras.Model(base_model2.input, outputs)\n",
    "\n",
    "# congelar capas\n",
    "for layer in base_model3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compilar el modelo.\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 7, 7, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 7, 7, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 7, 7, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 7, 7, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 7, 7, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1664)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 81536)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25088)        0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 81536)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 25088)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 51200)        0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 51200)        0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         166987776   dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         51382272    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         104859648   dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2048)         104859648   dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2048)         8192        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 2048)         8192        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 2048)         8192        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2048)         0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 2048)         0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2048)         4196352     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2048)         4196352     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2048)         8192        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 2048)         8192        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 2048)         8192        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2048)         0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2048)         0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2049        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2049        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            2049        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            2049        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4)            0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           50          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            11          dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 499,418,593\n",
      "Trainable params: 444,915,777\n",
      "Non-trainable params: 54,502,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mergedOutput = tf.keras.layers.Concatenate()([model_1.output,model_2.output,model_3.output,model_4.output])\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10, activation='relu')(mergedOutput)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden)\n",
    "model = tf.keras.Model(inputs=new_input, outputs=output)\n",
    "                # plot graph of ensemble\n",
    "            #plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "                # compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 330s 31s/step - loss: 0.6231 - accuracy: 0.6304 - val_loss: 0.6902 - val_accuracy: 0.4375\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 367s 37s/step - loss: 0.5470 - accuracy: 0.7888 - val_loss: 0.7239 - val_accuracy: 0.3125\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 316s 32s/step - loss: 0.5107 - accuracy: 0.8517 - val_loss: 0.5739 - val_accuracy: 0.9062\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 612s 64s/step - loss: 0.4792 - accuracy: 0.8865 - val_loss: 0.5385 - val_accuracy: 0.9062\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 253s 25s/step - loss: 0.4834 - accuracy: 0.8724 - val_loss: 0.5499 - val_accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
    "STEP_SIZE_VALID = val_gen.n // val_gen.batch_size\n",
    "\n",
    "history=model.fit(x = train_gen,\n",
    "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "          validation_data = val_gen,\n",
    "          validation_steps = STEP_SIZE_VALID,\n",
    "          epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 15s 3s/step - loss: 0.5668 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_gen, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: F:/X_ray_Models/e2_binary_model_4\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [0.5978471636772156,\n",
       "  0.5477563738822937,\n",
       "  0.49613797664642334,\n",
       "  0.4789096713066101,\n",
       "  0.4761456251144409],\n",
       " 'accuracy': [0.6792452931404114,\n",
       "  0.7798742055892944,\n",
       "  0.8773584961891174,\n",
       "  0.8899371027946472,\n",
       "  0.8773584961891174],\n",
       " 'val_loss': [0.6902251243591309,\n",
       "  0.7239302396774292,\n",
       "  0.5739426016807556,\n",
       "  0.5384764671325684,\n",
       "  0.549883246421814],\n",
       " 'val_accuracy': [0.4375, 0.3125, 0.90625, 0.90625, 0.90625]}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.save('F:/X_ray_Models/e2_binary_model_4')\n",
    "\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 35s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "\n",
    "#y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>=0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.67      0.70      0.68        20\n           1       0.68      0.65      0.67        20\n\n    accuracy                           0.68        40\n   macro avg       0.68      0.68      0.67        40\nweighted avg       0.68      0.68      0.67        40\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[14,  6],\n",
       "       [ 7, 13]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}